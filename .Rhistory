Endorsements <- endorsements_2020
# Cleaning up the Endorsements dataset
Endorsements <- rename(Endorsements, candidate_name = endorsee)
Endorsements <- as_tibble(Endorsements)
polls <- filter(polls, candidate_name == c("Amy Klobuchar", "Bernard Sanders","Elizabeth Warren", "Joseph R. Biden Jr.", "Michael Bloomberg", "Pete Buttigieg"))
polls <- select(polls, candidate_name, sample_size, start_date, party, pct)
unique(Endorsements$candidate_name)
toString(unique(polls$candidate_name))
unique(Endorsements$candidate_name)
unique(polls$candidate_name)
polls <- polls %>% mutate(candidate_name = recode(candidate_name, "Bernard Sanders" = "Bernie Sanders", "Joseph R. Biden Jr." = "Joe Biden"))
polls <- polls %>% mutate(candidate_name = recode(candidate_name, "Bernard Sanders" = "Bernie Sanders"))
polls <- polls %>% mutate(candidate_name = recode(candidate_name, "Joseph R. Biden Jr." = "Joe Biden"))
dems.race.2020 <- polls %>% inner_join(Endorsements, by = "candidate_name")
unique(dems.race.2020$candidate_name)
num_endorsements <- dems.race.2020 %>% filter(!is.na(candidate_name)) %>% group_by(candidate_name)
num_endorsements
num_endorsements <- dems.race.2020 %>% filter(!is.na(candidate_name)) %>% group_by(candidate_name)
num_endorsements %>% summarise(count = n())
colnames(num_endorsements)
num_endorsements <- dems.race.2020 %>% group_by(candidate_name) %>% summarise(count = n()) %>% filter(!is.na(candidate_name))
colnames(num_endorsements)
num_endorsements <- dems.race.2020 %>% group_by(candidate_name) %>% filter(!is.na(candidate_name)) %>% summarise(count = n())
colnames(num_endorsements)
num_endorsements <- dems.race.2020 %>% group_by(candidate_name) %>% filter(!is.na(candidate_name)) %>% summarise(count = n())
p <- ggplot(data = num_endorsements, mapping = aes(x = candidate_name, y = count)) +
geom_bar()
p
p <- ggplot(data = num_endorsements, mapping = aes(x = candidate_name, y = count)) +
geom_point()
p
p + theme_dark()
num_endorsements <- dems.race.2020 %>% group_by(candidate_name) %>% filter(!is.na(candidate_name)) %>% summarise(count = n())
p <- ggplot(data = num_endorsements, mapping = aes(x = candidate_name, y = count)) +
geom_point()
p + labs(title = "Who the Who's Who Think Should Win", x = "Number of Endorsements", y = "2020 Presidential Candidate") +
+ theme_void
num_endorsements <- dems.race.2020 %>% group_by(candidate_name) %>% filter(!is.na(candidate_name)) %>% summarise(count = n())
p <- ggplot(data = num_endorsements, mapping = aes(x = candidate_name, y = count)) +
geom_point()
p + labs(title = "Who the Who's Who Think Should Win", x = "Number of Endorsements", y = "2020 Presidential Candidate") +
+ theme_void()
num_endorsements <- dems.race.2020 %>% group_by(candidate_name) %>% filter(!is.na(candidate_name)) %>% summarise(count = n())
p <- ggplot(data = num_endorsements, mapping = aes(x = candidate_name, y = count)) +
geom_point()
p + labs(title = "Who the Who's Who Think Should Win", x = "Number of Endorsements", y = "2020 Presidential Candidate") +
theme_void()
num_endorsements <- dems.race.2020 %>% group_by(candidate_name) %>% filter(!is.na(candidate_name)) %>% summarise(count = n())
p <- ggplot(data = num_endorsements, mapping = aes(x = candidate_name, y = count)) +
geom_point()
p + labs(title = "Who the Who's Who Think Should Win", x = "Number of Endorsements", y = "2020 Presidential Candidate") +
theme_classic()
num_endorsements <- dems.race.2020 %>% group_by(candidate_name) %>% filter(!is.na(candidate_name)) %>% summarise(count = n())
p <- ggplot(data = num_endorsements, mapping = aes(x = candidate_name, y = count)) +
geom_point()
p + labs(title = "Who the Who's Who Think Should Win", x = "Number of Endorsements", y = "2020 Presidential Candidate") +
theme_light()
p + labs(title = "Who the Who's Who Think Should Win", x = "Number of Endorsements", y = "2020 Presidential Candidate") +
theme_light() +
theme(axis.text.y = element_text(angle = 60, hjust = 1), axis.text.x = element_text(angle = 60, hjust = 1))
theme_light() +
theme(axis.text.y = element_text(angle = 30, hjust = 1), axis.text.x = element_text(angle = 30, hjust = 1))
p + labs(title = "Who the Who's Who Think Should Win", x = "Number of Endorsements", y = "2020 Presidential Candidate") +
theme_light() +
theme(axis.text.y = element_text(angle = 30, hjust = 1), axis.text.x = element_text(angle = 30, hjust = 1))
p + labs(title = "Who the Who's Who Think Should Win in 2020", x = "Number of Endorsements", y = "2020 Presidential Candidate") +
theme_light() +
theme(axis.text.y = element_text(angle = 15, hjust = 1), axis.text.x = element_text(angle = 15, hjust = 1))
p + labs(title = "Who the Who's Who Think Should Win in 2020", x = "Number of Endorsements", y = "2020 Presidential Candidate") +
theme_light() +
theme(axis.text.y = element_text(angle = 15,), axis.text.x = element_text(angle = 15, hjust = 1))
p + labs(title = "Who the Who's Who Think Should Win in 2020", x = "Number of Endorsements", y = "2020 Presidential Candidate") +
theme_light() +
theme(axis.text.y = element_text(angle = 15,), axis.text.x = element_text(angle = 15))
p + labs(title = "Who the Who's Who Think Should Win in 2020", x = "Number of Endorsements", y = "2020 Presidential Candidate") +
theme_light() +
theme(axis.text.y = element_text(angle = 10,), axis.text.x = element_text(angle = 10))
p <- ggplot(data = num_endorsements, mapping = aes(x = candidate_name, fill = candidate_name)) +
geom_bar()
p + labs(title = "Who the Who's Who Think Should Win in 2020", x = "Number of Endorsements", y = "2020 Presidential Candidate") +
theme_light() +
theme(axis.text.y = element_text(angle = 10,), axis.text.x = element_text(angle = 10))
p <- ggplot(data = num_endorsements, mapping = aes(x = candidate_name, fill = count)) +
geom_bar()
p + labs(title = "Who the Who's Who Think Should Win in 2020", x = "Number of Endorsements", y = "2020 Presidential Candidate") +
theme_light() +
theme(axis.text.y = element_text(angle = 10,), axis.text.x = element_text(angle = 10))
p <- ggplot(data = num_endorsements, mapping = aes(x = count, fill = candidate_name) +
geom_bar()
p + labs(title = "Who the Who's Who Think Should Win in 2020", x = "Number of Endorsements", y = "2020 Presidential Candidate") +
theme_light() +
theme(axis.text.y = element_text(angle = 10,), axis.text.x = element_text(angle = 10))
num_endorsements <- dems.race.2020 %>% group_by(candidate_name) %>% filter(!is.na(candidate_name)) %>% summarise(count = n())
p <- ggplot(data = num_endorsements, mapping = aes(x = count, fill = candidate_name) +
geom_bar()
p + labs(title = "Who the Who's Who Think Should Win in 2020", x = "Number of Endorsements", y = "2020 Presidential Candidate") +
theme_light() +
theme(axis.text.y = element_text(angle = 10,), axis.text.x = element_text(angle = 10))
num_endorsements <- dems.race.2020 %>% group_by(candidate_name) %>% filter(!is.na(candidate_name)) %>% summarise(count = n())
p <- ggplot(data = num_endorsements, mapping = aes(x = candidate_name, fill = count) +
geom_bar()
p + labs(title = "Who the Who's Who Think Should Win in 2020", x = "Number of Endorsements", y = "2020 Presidential Candidate") +
theme_light() +
theme(axis.text.y = element_text(angle = 10,), axis.text.x = element_text(angle = 10))
p + labs(title = "Who the Who's Who Think Should Win in 2020", x = "Number of Endorsements", y = "2020 Presidential Candidate") +
theme_light() +
theme(axis.text.y = element_text(angle = 15), axis.text.x = element_text(angle = 15))
p <- ggplot(data = num_endorsements, mapping = aes(x = candidate_name, y = count)) +
geom_point()
p + labs(title = "Who the Who's Who Think Should Win in 2020", x = "Number of Endorsements", y = "2020 Presidential Candidate") +
theme_light() +
theme(axis.text.y = element_text(angle = 15), axis.text.x = element_text(angle = 15))
p <- ggplot(data = num_endorsements, mapping = aes(x = candidate_name, y = count)) +
geom_bar()
p + labs(title = "Who the Who's Who Think Should Win in 2020", x = "Number of Endorsements", y = "2020 Presidential Candidate") +
theme_light() +
theme(axis.text.y = element_text(angle = 15), axis.text.x = element_text(angle = 15))
num_endorsements <- dems.race.2020 %>% group_by(candidate_name) %>% filter(!is.na(candidate_name)) %>% summarise(count = n())
p <- ggplot(data = num_endorsements, mapping = aes(x = candidate_name, y = count)) +
geom_point()
p + labs(title = "Who the Who's Who Think Should Win in 2020", x = "Number of Endorsements", y = "2020 Presidential Candidate") +
theme_light() +
theme(axis.text.y = element_text(angle = 15), axis.text.x = element_text(angle = 15))
install.packages('tm')
# library(tm)
install.packages('lubridate')
# library(lubridate)
install.packages('wordcloud')
install.packages("lubridate")
library(tm)
library(lubridate)
library(wordcloud)
tweets <- read_csv('https://politicaldatascience.com/PDS/Datasets/trump_tweets.csv')
tweetsCopy <- tweets # Again, so we can alter tweets directly but don't have to call in read every time we want to look at the original
colnames(tweets)
tweets <- read.csv('https://politicaldatascience.com/PDS/Datasets/trump_tweets.csv')
tweetsCopy <- tweets # Again, so we can alter tweets directly but don't have to call in read every time we want to look at the original
colnames(tweets)
head(tweets$created_at)
tweets <- tweets %<% separate(created_at, c("Date_Published", "Time_Published"), sep = " ")
colnames(tweets)
tweets <- read.csv('https://politicaldatascience.com/PDS/Datasets/trump_tweets.csv')
tweetsCopy <- tweets # Again, so we can alter tweets directly but don't have to call in read every time we want to look at the original
tweets <- as.tibble(tweets)
tweets <- tweets %<% separate(created_at, c("Date_Published", "Time_Published"), sep = " ")
colnames(tweets)
tweets <- tweets %<% separate(created_at, c("Date_Published", "Time_Published"), sep = " ")
colnames(tweets)
tweets <- tweets %>% separate(created_at, c("Date_Published", "Time_Published"), sep = " ")
colnames(tweets)
library(tidyverse)
tweets <- as.tibble(tweets)
tweets <- tweets %>% separate(created_at, c("Date_Published", "Time_Published"), sep = " ")
colnames(tweets)
select(tweets, date_published)
tweets <- tweets %>% separate(created_at, c("date_published", "time_published"), sep = " ")
select(tweets, "date_published")
select(tweets, date_published)
tweets <- tweets %>% separate(created_at, c("date_published", "time_published"), sep = " ")
select(tweets, date_published)
tweets <- as.data.frame(tweets)
select(tweets, date_published)
colnames(tweets)
tweets <- tweets %>% separate(created_at, c("date_published", "time_published"), sep = " ")
tweets <- as.tibble(tweets)
tweets <- tweets %>% separate(created_at, c("date_published", "time_published"), sep = " ")
colnames(tweets)
tweets <- as.data.frame(tweets)
select(tweets, date_published)
colnames(tweets)
tweets <- read.csv('https://politicaldatascience.com/PDS/Datasets/trump_tweets.csv')
tweetsCopy <- tweets # Again, so we can alter tweets directly but don't have to call in read every time we want to look at the original
tweets <- as.tibble(tweets)
tweets <- tweets %>% separate(created_at, c("date_published", "time_published"), sep = " ")
colnames(tweets)
tweets <- as.data.frame(tweets)
select(tweets, date_published)
range(select(tweets, date_published))
date.data <- tweets %>% separate(created_at, c("month", "day", "year"), sep = "/")
monthRange <- range(select(date.data, month))
tweets <- tweetsCopy
tweets <- as.tibble(tweets)
tweets <- tweets %>% separate(created_at, c("date_published", "time_published"), sep = " ")
colnames(tweets)
tweets <- as.data.frame(tweets)
date.data <- tweets %>% separate(created_at, c("month", "day", "year"), sep = "/")
monthRange <- range(select(date.data, month))
tweets <- read.csv('https://politicaldatascience.com/PDS/Datasets/trump_tweets.csv')
tweetsCopy <- tweets # Again, so we can alter tweets directly but don't have to call in read every time we want to look at the original
tweets <- tweetsCopy
tweets <- as.tibble(tweets)
tweets <- tweets %>% separate(created_at, c("date_published", "time_published"), sep = " ")
colnames(tweets)
tweets <- as.data.frame(tweets)
date.data <- tweets %>% separate(created_at, c("month", "day", "year"), sep = "/")
monthRange <- range(select(date.data, month))
tweets <- read.csv('https://politicaldatascience.com/PDS/Datasets/trump_tweets.csv')
tweets <- as.tibble(tweets)
tweets <- tweets %>% separate(created_at, c("date_published", "time_published"), sep = " ")
colnames(tweets)
tweets <- as.data.frame(tweets)
date.data <- tweets %>% separate(date_published, c("month", "day", "year"), sep = "/")
monthRange <- range(select(date.data, month))
date.data$month
tweets <- as.data.frame(tweets)
date.data <- tweets %>% separate(date_published, c("month", "day", "year"), sep = "/")
monthRange <- range(select(date.data, as.numeric(month)))
sapply(month, as.numeric)
type(date.data)
class(date.data)
class(date.data$month)
as.numeric(date.data$month)
range(as.numeric(date.data$month))
dayRange = range(as.numeric(date.data$day))
yearRange = range(as.numeric(date.data$year))
dayRange
yearRange
filter(date.data, year == "2014")
monthRange = range(as.numeric(filter(date.data, year == "2014")))
monthRange
monthRange = range(as.numeric(unlist(filter(date.data, year == "2014"))))
monthRange
monthRange = range(as.numeric(filter(date.data, year == "2014"))$month)
monthRange
monthRange = range(as.numeric(unlist(filter(date.data, year == "2014"))$month))
monthRange
monthRange = range(as.numeric(unlist(filter(date.data, year == "2014")$month)))
monthRange
endMonth = range(as.numeric(unlist(filter(date.data, year == "2020")$month)))
endMonth
startDay = range(as.numeric(unlist(filter(date.data, year == "2014", month == "1")$day)))
startDay
endDay = range(as.numeric(unlist(filter(date.data, year == "2020", month == "2")$day)))
endDay
colnames(tweets)
tweets <- tweets %>% filter(source, test, date_published, time_published, retweet_count, favorite_count)
colnames(tweets)
tweets <- tweets %>% filter(source, text, date_published, time_published, retweet_count, favorite_count)
colnames(tweets)
tweets <- tweets %>% select(source, text, date_published, time_published, retweet_count, favorite_count)
colnames(tweets)
tweets <- tweets %>% arrange(desc(favorite_count))
most_liked <- tweets[1:5]
most_liked
size(most_liked)
dim(most_liked)
tweets <- tweets %>% arrange(desc(favorite_count))
most_liked <- tweets[,1:5]
dim(most_liked)
tweets <- tweets %>% arrange(desc(favorite_count))
most_liked <- tweets[,1:5]
dim(most_liked)
tweets <- tweets %>% arrange(desc(favorite_count))
most_liked <- tweets[1:5,]
dim(most_liked)
most_liked
# Finding top 5 most retweeted tweets
tweets <- tweets %>% arrange(desc(retweet_count))
most_retweeted <- tweets[1:5,]
most_retweeted
tweets <- read.csv('https://politicaldatascience.com/PDS/Datasets/trump_tweets.csv')
tweetsCopy <- tweets # So we can skip reading in again
tweets <- tweetsCopy
tweet_words <- tweets %>% mutate(text = stripWhitespace(text)) %>%
mutate(text = removeNumbers(text)) %>%
mutate(text = removePunctuation(text)) %>%
mutate(text = toLower(text)) %>%
mutate(text = removeWords(text, stopwords('en'))) %>%
mutate(text = removeWords(text, c("see", "people","new","want","one","even","must","need","done","back","just","going", "know","can","said","like","many","like","realdonaldtrump")))
tweet_words
tweets <- tweetsCopy
tweet_words <- tweets %>% select(text) %>% mutate(text = stripWhitespace(text)) %>%
mutate(text = removeNumbers(text)) %>%
mutate(text = removePunctuation(text)) %>%
mutate(text = toLower(text)) %>%
mutate(text = removeWords(text, stopwords('en'))) %>%
mutate(text = removeWords(text, c("see", "people","new","want","one","even","must","need","done","back","just","going", "know","can","said","like","many","like","realdonaldtrump")))
tweet_words
class(tweets$text)
as.character(tweets$text)
tweets$text = as.character(tweets$text)
class(tweets$text)
tweets$text = as.character(tweets$text)
tweet_words <- tweets %>% select(text) %>%
mutate(text = stripWhitespace(text)) %>%
mutate(text = removeNumbers(text)) %>%
mutate(text = removePunctuation(text)) %>%
mutate(text = toLower(text)) %>%
mutate(text = removeWords(text, stopwords('en'))) %>%
mutate(text = removeWords(text, c("see", "people","new","want","one","even","must","need","done","back","just","going", "know","can","said","like","many","like","realdonaldtrump")))
tweet_words
tweet_words <- tweets %>% select(text) %>%
mutate(text = stripWhitespace(text)) %>%
mutate(text = removeNumbers(text)) %>%
mutate(text = removePunctuation(text)) %>%
mutate(text = tolower(text)) %>%
mutate(text = removeWords(text, stopwords('en'))) %>%
mutate(text = removeWords(text, c("see", "people","new","want","one","even","must","need","done","back","just","going", "know","can","said","like","many","like","realdonaldtrump")))
tweet_words
class(tweet_words)
dim(tweet_words)
str.split(tweet_words)
tweet_words
tweet_words <- tweets %>% select(text) %>%
mutate(text = stripWhitespace(text)) %>%
mutate(text = removeNumbers(text)) %>%
mutate(text = removePunctuation(text)) %>%
mutate(text = tolower(text)) %>%
mutate(text = removeWords(text, stopwords('en'))) %>%
mutate(text = removeWords(text, c("see", "people","new","want","one","even","must","need","done","back","just","going", "know","can","said","like","many","like","realdonaldtrump", "rt")))
tweet_words
str_split(tweet_words)
str_split(tweet_words, " ")
str_split(tweet_words, " ")
sorted <- as.tibble(unlist(str_split(tweet_words, " "))) %>%
group_by(value) %>%
summarise(count = n()) %>%
arrange(count)
counts
sorted <- as.tibble(unlist(str_split(tweet_words, " "))) %>%
group_by(value) %>%
summarise(count = n()) %>%
arrange(count)
sorted
reverse(sorted)
class(sorted)
rev(sorted)
sorted[,53500:53550]
sorted[53500:53550]
as.dataframe(sorted[53500:53550])
as.data.frame(sorted[53500:53550])
as.data.frame(sorted[,53500:53550])
class(sorted)
dim(sorted)
sorted[1, 53514:53564]
sorted[1, c(53514:53564)]
sorted <- as.tibble(unlist(str_split(tweet_words, " "))) %>%
group_by(value) %>%
summarise(count = n()) %>%
arrange(desc(count))
sorted
tweet_words <- tweets %>% select(text) %>%
mutate(text = stripWhitespace(text)) %>%
mutate(text = removeNumbers(text)) %>%
mutate(text = removePunctuation(text)) %>%
mutate(text = tolower(text)) %>%
mutate(text = removeWords(text, stopwords('en'))) %>%
mutate(text = removeWords(text, c("see", "people","new","want","one","even","must","need","done","back","just","going", "know","can","said","like","many","like","realdonaldtrump", "rt"))) %>%
mutate(text = removeWords(text, c("")))
sorted <- as.tibble(unlist(str_split(tweet_words, " "))) %>%
group_by(value) %>%
summarise(count = n()) %>%
arrange(desc(count))
sorted
tweet_words <- tweets %>% select(text) %>%
mutate(text = stripWhitespace(text)) %>%
mutate(text = removeNumbers(text)) %>%
mutate(text = removePunctuation(text)) %>%
mutate(text = tolower(text)) %>%
mutate(text = removeWords(text, stopwords('en'))) %>%
mutate(text = removeWords(text, c("see", "people","new","want","one","even","must","need","done","back","just","going", "know","can","said","like","many","like","realdonaldtrump", "rt"))) %>%
mutate(text = removeWords(text, c("")))
sorted <- as.tibble(unlist(str_split(tweet_words, " "))) %>%
group_by(value) %>%
summarise(count = n()) %>%
arrange(desc(count))
sorted
tweet_words <- tweets %>% select(text) %>%
mutate(text = stripWhitespace(text)) %>%
mutate(text = removeNumbers(text)) %>%
mutate(text = removePunctuation(text)) %>%
mutate(text = tolower(text)) %>%
mutate(text = removeWords(text, stopwords('en'))) %>%
mutate(text = removeWords(text, c("see", "people","new","want","one","even","must","need","done","back","just","going", "know","can","said","like","many","like","realdonaldtrump", "rt"))) %>%
mutate(text = removeWords(text, c(""))) %>%
mutate(text = removeSpecialChars(text))
sorted <- as.tibble(unlist(str_split(tweet_words, " "))) %>%
group_by(value) %>%
summarise(count = n()) %>%
arrange(desc(count))
sorted
tweets <- tweetsCopy
tweets$text = as.character(tweets$text)
# A little function from Stack Overflow to remove everything that is not a letter
removeSpecialChars <- function(x) gsub("[^a-zA-Z]",x)
tweet_words <- tweets %>% select(text) %>%
mutate(text = stripWhitespace(text)) %>%
mutate(text = removeNumbers(text)) %>%
mutate(text = removePunctuation(text)) %>%
mutate(text = tolower(text)) %>%
mutate(text = removeWords(text, stopwords('en'))) %>%
mutate(text = removeWords(text, c("see", "people","new","want","one","even","must","need","done","back","just","going", "know","can","said","like","many","like","realdonaldtrump", "rt"))) %>%
mutate(text = removeWords(text, c(""))) %>%
mutate(text = removeSpecialChars(text))
sorted <- as.tibble(unlist(str_split(tweet_words, " "))) %>%
group_by(value) %>%
summarise(count = n()) %>%
arrange(desc(count))
sorted
class(sorted)
sorted(-c(1, 2, 6, 9))
sorted[-c(1, 2, 6, 9)]
sorted <- as.data.frame(sorted)
sorted[-c(1, 2, 6, 9)]
sorted <- as.data.frame(sorted)
sorted[-c(1, 2, 6, 9),]
tweets <- tweetsCopy
tweets$text = as.character(tweets$text)
tweet_words <- tweets %>% select(text) %>%
mutate(text = stripWhitespace(text)) %>%
mutate(text = removeNumbers(text)) %>%
mutate(text = removePunctuation(text)) %>%
mutate(text = tolower(text)) %>%
mutate(text = removeWords(text, stopwords('en'))) %>%
mutate(text = removeWords(text, c("see", "people","new","want","one","even","must","need","done","back","just","going", "know","can","said","like","many","like","realdonaldtrump", "rt"))) %>%
mutate(text = removeWords(text, c(""))) %>%
sorted <- as.tibble(unlist(str_split(tweet_words, " "))) %>%
group_by(value) %>%
summarise(count = n()) %>%
arrange(desc(count))
sorted <- as.data.frame(sorted)
sorted[-c(1, 2, 6, 9),]
class(sorted)
dim(sorted)
sorted[1:1]
sorted[1,1]
sorted[-c(1, 2, 6, 9),]
sorted <- sorted[-c(1, 2, 6, 9),]
sorted[1,1]
sorted[,1]
tweets <- tweetsCopy
tweets$text = as.character(tweets$text)
tweet_words <- tweets %>% select(text) %>%
mutate(text = stripWhitespace(text)) %>%
mutate(text = removeNumbers(text)) %>%
mutate(text = removePunctuation(text)) %>%
mutate(text = tolower(text)) %>%
mutate(text = removeWords(text, stopwords('en'))) %>%
mutate(text = removeWords(text, c("see", "people","new","want","one","even","must","need","done","back","just","going", "know","can","said","like","many","like","realdonaldtrump", "rt"))) %>%
mutate(text = removeWords(text, c(""))) %>%
# Get frequencies
sorted <- as.tibble(unlist(str_split(tweet_words, " "))) %>%
group_by(value) %>%
summarise(count = n()) %>%
arrange(desc(count))
sorted <- as.data.frame(sorted)
sorted[,1]
#sorted <- sorted[-c(1, 2, 6, 9),]
#sorted[,1]
tweets <- read.csv('https://politicaldatascience.com/PDS/Datasets/trump_tweets.csv')
tweets$text = as.character(tweets$text)
tweet_words <- tweets %>% select(text) %>%
mutate(text = stripWhitespace(text)) %>%
mutate(text = removeNumbers(text)) %>%
mutate(text = removePunctuation(text)) %>%
mutate(text = tolower(text)) %>%
mutate(text = removeWords(text, stopwords('en'))) %>%
mutate(text = removeWords(text, c("see", "people","new","want","one","even","must","need","done","back","just","going", "know","can","said","like","many","like","realdonaldtrump", "rt"))) %>%
mutate(text = removeWords(text, c(""))) %>%
# Get frequencies
sorted <- as.tibble(unlist(str_split(tweet_words, " "))) %>%
group_by(value) %>%
summarise(count = n()) %>%
arrange(desc(count))
sorted <- as.data.frame(sorted)
sorted[,1]
#sorted <- sorted[-c(1, 2, 6, 9),]
#sorted[,1]
sorted <- as.tibble(unlist(str_split(tweet_words, " "))) %>%
group_by(value) %>%
summarise(count = n()) %>%
arrange(desc(count))
sorted <- as.data.frame(sorted)
#sorted[,1]
sorted <- sorted[-c(25, 31, 44),]
sorted[,1]
sorted <- as.tibble(unlist(str_split(tweet_words, " "))) %>%
group_by(value) %>%
summarise(count = n()) %>%
arrange(desc(count))
sorted <- as.data.frame(sorted)
#sorted[,1]
#sorted <- sorted[-c(1, 225, 31, 44),]
sorted[,1]
sorted <- as.tibble(unlist(str_split(tweet_words, " "))) %>%
group_by(value) %>%
summarise(count = n()) %>%
arrange(desc(count))
sorted <- as.data.frame(sorted)
sorted <- sorted[-c(1, 2, 6, 9, 29, 35, 48),]
sorted[,1]
wordcloud(words = sorted$value, freq = sorted$count, min.freq=3, max.words=50)
wordcloud(words = sorted$value, freq = sorted$count, min.freq=3, max.words=50, colors=c("chartreuse", "cornflowerblue", "darkorange"))
wordcloud(words = sorted$value, freq = sorted$count, min.freq=3, max.words=50, colors=c("chartreuse", "cornflowerblue", "darkorange"))
wordcloud(words = sorted$value, freq = sorted$count, min.freq=3, max.words=50, colors=c("chartreuse", "cornflowerblue", "darkorange"))
wordcloud(words = sorted$value, freq = sorted$count, min.freq=3, max.words=50, colors=c("red", "blue", "navy"))
input <- Corpus(VectorSource(sorted))
DTM <- TermDocumentMatrix(corpus, control=list(weighting = weightTfIdf))
DTM
DTM <- TermDocumentMatrix(input, control=list(weighting = weightTfIdf))
DTM
findMostFreqTerms(DTM, n = 50)
input <- Corpus(VectorSource(sorted[,1]))
DTM <- TermDocumentMatrix(input, control=list(weighting = weightTfIdf))
findMostFreqTerms(DTM, n = 50)
class(findMostFreqTerms(DTM, n = 50))
class(unlist(findMostFreqTerms(DTM, n = 50)))
unlist(findMostFreqTerms(DTM, n = 50))
findFreqTerms(DTM, lowfreq = 0.8)
class(findFreqTerms(DTM, lowfreq = 0.8))
findFreqTerms(DTM, lowfreq = 0.8)[1]
findFreqTerms(DTM, lowfreq = 0.8)[1:50]
